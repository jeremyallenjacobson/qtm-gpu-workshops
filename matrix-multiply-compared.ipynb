{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c76f78fe-7f0d-4c85-ae6c-0957ffe60269",
   "metadata": {},
   "source": [
    "# Matrix multiply speedup: 63,000 X?\n",
    "Let's code it in pure python, then compare with Numpy (C) on CPU, Pytorch and Tensorflow on GPU.\n",
    "\n",
    "Let's write down two matrices and multiply them using Python.\n",
    "\n",
    "This will also serve as a five minute introduction to Python!\n",
    "\n",
    "The matrices we will use are the 2x2 matrices below.\n",
    "$$ \n",
    "A =\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\text{ }\n",
    "B =\\begin{bmatrix}\n",
    "5 & 6 \\\\\n",
    "7 & 8 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "A list is a Python data type that is commonly used when working with arrays. In the frameworks we will use, one common way to define a matrix is as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fdc1a39-693b-49e0-bbfc-13533bc4fdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [[1,2],[3,4]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a820993c-9533-4029-8f22-4011ba8551e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "044ac557-f5b1-41a5-a6e7-7d55c895c19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa7907f-4d4e-4694-be58-79654f52b742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[3, 4]\n"
     ]
    }
   ],
   "source": [
    "for row in A:\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726b86a8-52ce-4ca4-a483-c929a268135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = [[5,6],[7,8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8fb78a4-ad47-43cf-9ae6-fb5d56f6c458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9952f3ee-a097-4612-9fc0-7b0772fd346b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "552a77c1-ca87-445f-85a3-a6d05115fa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 8]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6057d94-6dfb-42bc-8dff-d22df3692b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6]\n",
      "[7, 8]\n"
     ]
    }
   ],
   "source": [
    "row1_B = B[0]\n",
    "row2_B = B[1]\n",
    "print(row1_B)\n",
    "print(row2_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fcf3c68-ccd9-4f2e-b61f-0cc42351cc2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_1_2 = B[0][1]\n",
    "element_1_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf9260c-7901-47ad-8465-4600476efffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7739aa-13bd-4bd9-b339-4753462b5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply(A,B):\n",
    "    AB = [[0,0],[0,0]] # Create matrix of zeros\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            AB[i][j] = sum(A[i][k]*B[k][j] for k in range(2))\n",
    "    return AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e4aa3948-a28c-4441-9d9a-8d9c6a69185b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function matrix_multiply in module __main__:\n",
      "\n",
      "matrix_multiply(A, B)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(matrix_multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a72ed067-a67a-4f1e-84af-7c65fc3a89f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 22], [43, 50]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_multiply(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea686a-4c65-4aee-85eb-e6302d61baba",
   "metadata": {},
   "source": [
    "The result is \n",
    "$$ \n",
    "\\begin{bmatrix}\n",
    "1 & 2 \\\\\n",
    "3 & 4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "5 & 6 \\\\\n",
    "7 & 8 \\\\\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "19 & 22 \\\\\n",
    "43 & 50 \\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe4f45d-32da-44db-84ee-4517168d21d7",
   "metadata": {},
   "source": [
    "Below we write a Python function to multiply square matrices of any size. We are not interested in optimizing its runtime, rather we focus on writing a function that reads like the mathematical operation. Specifically the fact that the $i,j$ entry in the result $AB$ is given by the formula below.\n",
    "$$\n",
    "AB_{i,j} = \\sum_{k=1}^n A_{i,k}B_{k,j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a60a9928-1073-47b8-965e-b8157b4fbc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_multiply(A,B):\n",
    "    \"\"\"Multiply square matrices and return result\"\"\"\n",
    "    m = len(A) \n",
    "    AB = [[0]*m for i in range(m)] # create AB as matrix of zeros then fill in results \n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            AB[i][j] = sum(A[i][k]*B[k][j] for k in range(m))\n",
    "    \n",
    "    return AB\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d57402-887a-49b5-b92e-64f84eb7b838",
   "metadata": {},
   "source": [
    "Let's create a matrix initialized with random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "de189aec-64a8-4027-9186-93116087226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96449ade-2b6c-4630-9421-dab2294c9977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randrange(10) #random number between 0 and m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3859881e-e872-4678-aa56-1b41f7b84e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 850 # matrix size 850\n",
    "A = [[random.randrange(m) for j in range(m)] for i in range(m)]\n",
    "B = [[random.randrange(m) for j in range(m)] for i in range(m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72014155-eff2-4bae-8180-7e812bfb8c78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 4s ± 547 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "matrix_multiply(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97930bdb-49bb-4710-b39a-24e85b21bcce",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implement in Numpy\n",
    "Numpy is a Python package with numerical arrays similar to those found in R, C and Fortran. So they are like the lists above but all elements must be of the same numeric type such as a float or int. Numpy sends matrix calculations to numerical libraries written in C (or if you want, to languages linkable to C, such as Fortran).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8da0151-eda2-4150-8acd-0e8b4bb06c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A_np = np.array(A)\n",
    "B_np = np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8ec50f1-cad7-4e50-8e4a-feca90c29b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 706, 792, ..., 163, 389, 801],\n",
       "       [653, 208, 833, ..., 495, 381, 278],\n",
       "       [ 38,  77, 609, ..., 769, 593,  90],\n",
       "       ...,\n",
       "       [431, 531,  39, ..., 204, 780, 262],\n",
       "       [704, 669, 542, ...,  86, 164, 154],\n",
       "       [771, 229,  77, ...,   4, 539, 164]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07d7d106-33b7-4c02-9bf3-8da35cd425cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "693 ms ± 9.88 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.matmul(A_np,B_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9367f0-6916-417f-b3cf-200534235e0c",
   "metadata": {},
   "source": [
    "So how much faster is that?\n",
    "Let's say it was 600ms. The Python calculation was about 60 seconds, or 60000 ms. Hence Numpy was 100 X faster! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8bfbe-40b7-4082-b136-7b17fa01c290",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "First let's try it on the CPU. It should be about the same speed as Numpy as it should call to the same C libraries.\n",
    "Then we will move the data to the GPU and perform the matrix multiply there.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f1de9d6-2fee-491c-9b29-ef1a323392c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e25052-f534-4f51-a26e-c374b2967c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_t = torch.tensor(A)\n",
    "B_t = torch.tensor(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a49d744a-d028-4385-b486-614f7a837549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.7 ms ± 1.26 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.matmul(A_t,B_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294824c5-f336-438b-b9ef-dbd1539ad77d",
   "metadata": {},
   "source": [
    "Surprisingly this was a 10X improvement over Numpy. As far as I know there is no reason to expect such an improvement in general. Performance for matrix multiply strongly depends on the [BLAS](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) library to which the NumPy and Pytorch implementation relies on. It may be Numpy is using an older library.\n",
    "In any case, we are at a 1000 X improvement over pure Python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c84a4f-394d-4551-8a2e-45b499aa3601",
   "metadata": {},
   "source": [
    "# Let's try on the GPU\n",
    "First we check that GPU's are available to us.\n",
    "One way to do this is from the command line using the command `nvidia-smi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08f1389b-74da-49aa-8ea8-6d9d7a17050b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Nov  3 12:48:07 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    Off  | 00000000:1B:00.0 Off |                  Off |\n",
      "| 30%   31C    P8    27W / 300W |      0MiB / 48685MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8443e56b-fd92-4020-9ec4-d489ff7ae84e",
   "metadata": {},
   "source": [
    "We can also use utilities in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6782514-ad65-49ea-9968-4669d66b77b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5201b6-53c4-40b0-b919-aaed4fc850e2",
   "metadata": {},
   "source": [
    "How many (I requested 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "155424d5-1a18-41b2-9dde-c6813a4884a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4307b-20da-42fc-b798-682778153da2",
   "metadata": {},
   "source": [
    "What GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4ae3c9d2-20bb-4690-af17-df5115fbd9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA RTX A6000'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830ea41-f51e-4328-b847-226ddd76d8a9",
   "metadata": {},
   "source": [
    "How much GPU memory currently used?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a91d78f8-184c-41b1-ae82-c62563f4e76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory allocated: 0.0 GB\n",
      "Memory reserved:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "print('Memory allocated:', round(torch.cuda.memory_allocated()/1024**3,4), 'GB')\n",
    "print('Memory reserved:   ', round(torch.cuda.memory_reserved()/1024**3,4), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa574e6-af02-481f-8b73-291dc94b92bf",
   "metadata": {},
   "source": [
    "First we move the matrices from the CPU memory to the GPU memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "121ec524-0685-4f25-bcb9-2e9daa047961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 89, 701, 616,  ..., 521, 488, 227],\n",
       "        [753, 216, 821,  ..., 569, 595, 363],\n",
       "        [741,  88, 416,  ..., 500, 712, 758],\n",
       "        ...,\n",
       "        [118, 553, 492,  ..., 490, 582, 138],\n",
       "        [ 86,  79, 353,  ..., 200, 308, 547],\n",
       "        [476, 444,  81,  ..., 108, 428, 243]], device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_t.to('cuda')\n",
    "B_t.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2429ec3a-5d0d-41a2-970f-9d7de5785de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory reserved:    0.0215 GB\n"
     ]
    }
   ],
   "source": [
    "print('Memory reserved:   ', round(torch.cuda.memory_reserved()/1024**3,4), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9ac0d9f-f52e-4fa0-97c6-f4c31885289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79.5 ms ± 922 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "# ensure that context initialization finish before you start measuring time\n",
    "torch.matmul(A_t,B_t)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7566632-b562-4b15-9153-236cc86610da",
   "metadata": {},
   "source": [
    "No speed up? Let's investigate the data type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4965363f-45ce-46ee-a59b-152e11652a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_t.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93545fe8-2ac9-4b88-920e-360708c47b42",
   "metadata": {},
   "source": [
    "Another consideration is the matrix size. Let's investigate matrix multiply for bigger matrices. We create two numpy arrays below of size `n` by `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0cdebee3-a19d-43a7-b8e1-fb06089d6413",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "C = np.random.rand(n,n)\n",
    "D = np.random.rand(n,n)\n",
    "C_t = torch.tensor(C).to(\"cuda\")\n",
    "D_t = torch.tensor(D).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8673caf-57fb-4ee6-b034-3030c2a5d0bb",
   "metadata": {},
   "source": [
    "How much bigger are these matrices?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41b60bd6-cd19-4716-84dc-442612ba6702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory reserved:    1.5137 GB\n"
     ]
    }
   ],
   "source": [
    "print('Memory reserved:   ', round(torch.cuda.memory_reserved()/1024**3,4), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8831568-53bb-4218-b02f-107fe6334019",
   "metadata": {},
   "source": [
    "What is the speed without GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54a6600e-8f39-40e0-8b8d-f07fea418551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.6 s ± 169 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "np.matmul(C,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7173201d-9dc5-42e8-853f-581957f80902",
   "metadata": {},
   "source": [
    "And on GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e893bae-6f1e-487c-82db-ec5a95f0c9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.56 s ± 12.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "torch.matmul(C_t,D_t)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0db0cf-cc48-4903-bd00-a3137efd40f5",
   "metadata": {},
   "source": [
    "We add `torch.cuda.synchronize()` to tell Python to wait for the GPU computation to finish before completing the timing. Otherwise, as soon as the computation is handed off to the GPU, `timeit` reports it finished, giving incorrect timings. \n",
    "\n",
    "Another way to time the GPU computation is with `torch.cuda.Event()`. Let's see how the timings compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "44ed2224-d29e-41e8-ad58-a939ee17eeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.575721923828125\n"
     ]
    }
   ],
   "source": [
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "torch.matmul(C_t,D_t)\n",
    "end.record()\n",
    "\n",
    "# Waits for everything to finish running\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "print(start.elapsed_time(end)/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9262ad-25f2-43a9-9e23-73586835057b",
   "metadata": {},
   "source": [
    "We get the same result, so that is comforting!\n",
    "\n",
    "Next, before we do new computations with new variables we will remove these matrices from the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4af6911c-d82e-440b-838f-d316b9d3ef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "del C_t\n",
    "del D_t\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b9952-e28a-4437-9ad4-c0a64885654c",
   "metadata": {},
   "source": [
    "Let's check memory now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cc5bfb7-467e-4ab3-91d1-ac797cd8a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory reserved:    0.0195 GB\n"
     ]
    }
   ],
   "source": [
    "print('Memory reserved:   ', round(torch.cuda.memory_reserved()/1024**3,4), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445f126b-fbfb-4b9f-a7d5-7d35c0f7a37c",
   "metadata": {},
   "source": [
    "## Optimizations: Single and half precision, matrix sizing\n",
    "Next we explore changing the datatype type and the matrix size. As we have 336 Tensor cores each optimized for 4x4 block multiplication, let's try a matrix of size 1344x1344, where 1344=4*336. We will loop the computation to have it perform 1000 matrix multiplies and time that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf436274-3b09-49f8-9746-7f3eb551a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1344\n",
    "C = np.random.rand(n,n)\n",
    "D = np.random.rand(n,n)\n",
    "C_t = torch.tensor(C)\n",
    "D_t = torch.tensor(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8a03853f-3394-4696-bc51-58d5c8a904f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(C.dtype)\n",
    "print(C_t.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93e4d7-0519-4ee5-a84b-53d87b9ee7c8",
   "metadata": {},
   "source": [
    "Next we create double precision on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73afe39b-4be9-4198-9c88-88c2710cd123",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_td = torch.cuda.DoubleTensor(C)\n",
    "D_td = torch.cuda.DoubleTensor(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "129a28cb-8cc5-4ef5-aead-70263588b771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "print(C_td.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f02150-d32f-4708-a829-74e744ffe915",
   "metadata": {},
   "source": [
    "Next, single precision on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "98bd520e-efc3-41d8-8e2e-5f340fe70027",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_ts = torch.cuda.FloatTensor(C)\n",
    "D_ts = torch.cuda.FloatTensor(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f54dac7d-051c-4d84-8755-a4d26a4bd0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(C_ts.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c3ee8f-a4b8-4e8a-9f0a-e7b751a3428d",
   "metadata": {},
   "source": [
    "Finally, half precision on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9bce9a3e-a2dc-4c2a-9dfb-dc93105abdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_th = torch.cuda.HalfTensor(C)\n",
    "D_th = torch.cuda.HalfTensor(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8cb27d17-7ca1-4c04-b2fd-27a509af02ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "print(C_th.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f510171-d45b-4d25-922d-8053057ebbaf",
   "metadata": {},
   "source": [
    "Let's try the computation now with these different precisions.\n",
    "\n",
    "First double precision on the CPU. Recall, a similar computation earlier was already ~1000 X faster than pure Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "137c9ab2-b65b-4ade-ad2a-1ad5173f60d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.24 s ± 93.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(100):\n",
    "    torch.matmul(C_t,D_t)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7476b1-4ae3-4121-8ad8-70314f3b1db8",
   "metadata": {},
   "source": [
    "Next, double precision on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51620d0c-9894-4422-b4dd-56be7539184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "899 ms ± 47 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(100):\n",
    "    torch.matmul(C_td,D_td)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1ab4c1-982f-49f5-b400-fe42ab12158f",
   "metadata": {},
   "source": [
    "So here we see a 100 X improvement over the CPU, hence we are at ~100,000 X pure Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c4de1a-4149-424c-9508-a12b8a974dee",
   "metadata": {},
   "source": [
    "Now, single precision on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4ccfe6a-c724-45f4-aa2a-b790ae14aa86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.3 ms ± 34.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(100):\n",
    "    torch.matmul(C_ts,D_ts)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd3d09-b034-4e7d-9c83-8f787499bb10",
   "metadata": {},
   "source": [
    "Now we are at ~100X double precision on GPU.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2337f7-0343-4ada-ae80-68087c87bae4",
   "metadata": {},
   "source": [
    "Finally, half precision on the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c3b1526-5477-4d8d-a07e-dfad4928d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.81 ms ± 2.72 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for i in range(100):\n",
    "    torch.matmul(C_th,D_th)\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe39fdc-759b-455a-a9c0-fad83a0a0103",
   "metadata": {},
   "source": [
    "We are at 2X single precision. For a grand total of 20,000,000 X pure Python!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
